{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3ab158-3494-4659-b5c7-8c0b41eaee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Exemplo de munic√≠pios do TO:\n",
      "     COD_UF      COD                  NOME             nome_norm\n",
      "311      17  1700251           Abreul√¢ndia           abreulandia\n",
      "312      17  1700301         Aguiarn√≥polis         aguiarnopolis\n",
      "313      17  1700350  Alian√ßa do Tocantins  alianca do tocantins\n",
      "314      17  1700400                 Almas                 almas\n",
      "315      17  1700707              Alvorada              alvorada\n",
      "üìÇ Arquivos encontrados: ['C:/Users/Valentine/Artigo_Mapitos/data_raw/degradacao.csv']\n",
      "üîß Processando degradacao.csv ...\n",
      "‚úÖ Registros consolidados: 1325\n",
      "üì¶ Arquivo final exportado para: C:/Users/Valentine/Artigo_Mapitos/data_clean/01_Municipios_Normalizados\\01_Deg_mun.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Normaliza√ß√£o dos munic√≠pios e cruzamento com tabela IBGE (vers√£o ajustada para estrutura: COD_UF, COD, NOME)\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import unidecode\n",
    "from rapidfuzz import process\n",
    "\n",
    "# %% 1. Carregar lista oficial do IBGE\n",
    "url_ibge = \"C:/Users/Valentine/Artigo_Mapitos/data_raw/data_auxiliar/IBGE_mun.csv\"\n",
    "ibge = pd.read_csv(url_ibge)\n",
    "\n",
    "# Filtrar Tocantins (COD_UF = 17)\n",
    "ibge_to = ibge[ibge[\"COD_UF\"] == 17].copy()\n",
    "\n",
    "# Normalizar nome\n",
    "ibge_to[\"nome_norm\"] = ibge_to[\"NOME\"].str.lower().apply(unidecode.unidecode)\n",
    "\n",
    "print(\"üìò Exemplo de munic√≠pios do TO:\")\n",
    "print(ibge_to.head())\n",
    "\n",
    "# %% 2. Fun√ß√µes auxiliares\n",
    "def normalizar_nome(nome):\n",
    "    if pd.isna(nome):\n",
    "        return \"\"\n",
    "    return unidecode.unidecode(str(nome).strip().lower())\n",
    "\n",
    "def melhor_match(municipio, lista_ref):\n",
    "    if not municipio:\n",
    "        return None\n",
    "    match, score, _ = process.extractOne(municipio, lista_ref)\n",
    "    return match if score > 80 else None\n",
    "\n",
    "# %% 3. Processar CSVs\n",
    "input_path = \"C:/Users/Valentine/Artigo_Mapitos/data_raw/degradacao.csv\"\n",
    "arquivos = glob.glob(input_path)\n",
    "\n",
    "print(\"üìÇ Arquivos encontrados:\", arquivos)\n",
    "\n",
    "dfs_processados = []\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    df = pd.read_csv(arquivo)\n",
    "    print(f\"üîß Processando {os.path.basename(arquivo)} ...\")\n",
    "\n",
    "    # Detectar a coluna de munic√≠pio (casos como 'municipio__', 'Munic√≠pio', etc)\n",
    "    col_munic = next((c for c in df.columns if \"munic\" in c.lower()), None)\n",
    "\n",
    "    if not col_munic:\n",
    "        print(\"‚ö†Ô∏è Nenhuma coluna de munic√≠pio encontrada, pulando este arquivo.\")\n",
    "        continue\n",
    "\n",
    "    # Normalizar nomes\n",
    "    df[\"municipio_norm\"] = df[col_munic].apply(normalizar_nome)\n",
    "\n",
    "    # Merge direto com nomes normalizados\n",
    "    merged = df.merge(ibge_to, left_on=\"municipio_norm\", right_on=\"nome_norm\", how=\"left\")\n",
    "\n",
    "    # Fuzzy matching para os que n√£o bateram\n",
    "    mask_na = merged[\"COD\"].isna()\n",
    "    if mask_na.any():\n",
    "        lista_ref = ibge_to[\"nome_norm\"].tolist()\n",
    "        merged.loc[mask_na, \"nome_match\"] = merged.loc[mask_na, \"municipio_norm\"].apply(\n",
    "            lambda x: melhor_match(x, lista_ref)\n",
    "        )\n",
    "        merged = merged.merge(\n",
    "            ibge_to[[\"COD\", \"COD_UF\", \"NOME\", \"nome_norm\"]],\n",
    "            left_on=\"nome_match\",\n",
    "            right_on=\"nome_norm\",\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_fuzzy\"),\n",
    "        )\n",
    "        merged[\"codigo_final\"] = merged[\"COD\"].combine_first(merged[\"COD_fuzzy\"])\n",
    "        merged[\"uf_final\"] = merged[\"COD_UF\"].combine_first(merged[\"COD_UF_fuzzy\"])\n",
    "        merged[\"municipio_ibge\"] = merged[\"NOME\"].combine_first(merged[\"NOME_fuzzy\"])\n",
    "    else:\n",
    "        merged[\"codigo_final\"] = merged[\"COD\"]\n",
    "        merged[\"uf_final\"] = merged[\"COD_UF\"]\n",
    "        merged[\"municipio_ibge\"] = merged[\"NOME\"]\n",
    "\n",
    "    merged = merged.rename(columns={col_munic: \"municipio_original\"})\n",
    "    dfs_processados.append(merged)\n",
    "\n",
    "# %% 4. Consolidar e exportar\n",
    "if dfs_processados:\n",
    "    df_final = pd.concat(dfs_processados, ignore_index=True)\n",
    "    print(\"‚úÖ Registros consolidados:\", len(df_final))\n",
    "else:\n",
    "    df_final = pd.DataFrame()\n",
    "    print(\"‚ö†Ô∏è Nenhum arquivo processado.\")\n",
    "\n",
    "output_dir = \"C:/Users/Valentine/Artigo_Mapitos/data_clean/01_Municipios_Normalizados\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"01_Deg_mun.csv\")\n",
    "\n",
    "df_final.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"üì¶ Arquivo final exportado para:\", output_file)\n",
    "\n",
    "# Agora cada linha tem:\n",
    "# - municipio_original (do seu CSV)\n",
    "# - municipio_norm (normalizado)\n",
    "# - municipio_ibge (nome oficial IBGE)\n",
    "# - codigo_final (c√≥digo IBGE)\n",
    "# - uf_final (UF)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tocantins_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
